<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kirill Pavlov</title>
    <link>http://kirillpavlov.com/</link>
    <description>Recent content on Kirill Pavlov</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 21 Feb 2016 00:20:45 +0800</lastBuildDate>
    <atom:link href="http://kirillpavlov.com/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Top 5 features released in spark 1.6</title>
      <link>http://kirillpavlov.com/blog/2016/02/21/top-5-features-released-in-spark-1.6/</link>
      <pubDate>Sun, 21 Feb 2016 00:20:45 +0800</pubDate>
      
      <guid>http://kirillpavlov.com/blog/2016/02/21/top-5-features-released-in-spark-1.6/</guid>
      <description>

&lt;p&gt;Spark version 1.6 &lt;a href=&#34;https://spark.apache.org/releases/spark-release-1-6-0.html&#34;&gt;has been released&lt;/a&gt; on January 4th, 2016.
Compared to the previous version, it has significant improvements. This article covers top 5 of them.&lt;/p&gt;

&lt;h3 id=&#34;1-partition-by-column:8ab4cd76c2e48d03608ec5aca1374ea6&#34;&gt;1. Partition by column&lt;/h3&gt;

&lt;p&gt;The idea is to have more control on RDD&amp;rsquo;s partitioning.
Sometimes data needs to be joined and grouped by certain key, such as user_id.
To minify data reshuffling, one may possible to store chunks of objects with the same key within the same data node.&lt;/p&gt;

&lt;p&gt;This feature &lt;a href=&#34;https://cwiki.apache.org/confluence/display/Hive/LanguageManual+SortBy#LanguageManualSortBy-SyntaxofClusterByandDistributeBy&#34;&gt;exists in Hive&lt;/a&gt; and has been &lt;a href=&#34;https://issues.apache.org/jira/browse/SPARK-11410&#34;&gt;ported to spark&lt;/a&gt;.
Example of usage:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val df = sc.parallelize(Array(
    (&amp;quot;A&amp;quot;, 1), (&amp;quot;B&amp;quot;, 2), (&amp;quot;C&amp;quot;, 3), (&amp;quot;A&amp;quot;, 4)
)).toDF(&amp;quot;key&amp;quot;, &amp;quot;value&amp;quot;)
val partitioned = df.repartition($&amp;quot;key&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;2-groupeddata-pivot:8ab4cd76c2e48d03608ec5aca1374ea6&#34;&gt;2. GroupedData Pivot&lt;/h3&gt;

&lt;p&gt;This feature is about data presentation: if we need to transform adjacency list to adjacency matrix or convert long narrow RDD to the matrix - pivot is our friend.
Python has pivot functionality in Pandas DataFrames: &lt;a href=&#34;http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.unstack.html#pandas.DataFrame.unstack&#34;&gt;unstack&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val df = sc.parallelize(Array(
    (&amp;quot;one&amp;quot;, &amp;quot;A&amp;quot;, 1), (&amp;quot;one&amp;quot;, &amp;quot;B&amp;quot;, 2), (&amp;quot;two&amp;quot;, &amp;quot;A&amp;quot;, 3), (&amp;quot;two&amp;quot;, &amp;quot;B&amp;quot;, 4)
)).toDF(&amp;quot;key1&amp;quot;, &amp;quot;key2&amp;quot;, &amp;quot;value&amp;quot;)
df.show()

+----+----+-----+
|key1|key2|value|
+----+----+-----+
| one|   A|    1|
| one|   B|    2|
| two|   A|    3|
| two|   B|    4|
+----+----+-----+
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.GroupedData&#34;&gt;GroupedData.pivot&lt;/a&gt; allows making values from columns &lt;em&gt;key1&lt;/em&gt; or &lt;em&gt;key2&lt;/em&gt; new columns.
For example:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;df.groupBy(&amp;quot;key1&amp;quot;).pivot(&amp;quot;key2&amp;quot;).sum(&amp;quot;value&amp;quot;).show()

+----+-+-+
|key1|A|B|
+----+-+-+
| one|1|2|
| two|3|4|
+----+-+-+
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Usually, data to be pivoted is not big and to avoid reshuffling, it makes sense to use &lt;code&gt;coalesce&lt;/code&gt; first.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;// Better to combine data within one data node before pivot
val groupedData = df.groupBy(&amp;quot;key1&amp;quot;).coalesce(1).cache()
groupedData.pivot(&amp;quot;key2&amp;quot;).sum(&amp;quot;value&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;3-standard-deviation-calculation:8ab4cd76c2e48d03608ec5aca1374ea6&#34;&gt;3. Standard deviation calculation&lt;/h3&gt;

&lt;p&gt;Spark is not yet mature in terms of statistics calculation. For example, it does not allow to &lt;a href=&#34;https://stackoverflow.com/questions/28158729/how-can-i-calculate-exact-median-with-apache-spark#answer-28160731&#34;&gt;calculate the median&lt;/a&gt; value of the column. One of the reasons is that linear algorithm could not be generalized to distributed RDD.&lt;/p&gt;

&lt;p&gt;Simple standard deviation was introduced only in spark 1.6.
A Potential problem with custom calculation could be with type overflow.
Example of usage:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;df.agg(stddev(&amp;quot;value&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;4-simplified-outer-join:8ab4cd76c2e48d03608ec5aca1374ea6&#34;&gt;4. Simplified outer join&lt;/h3&gt;

&lt;p&gt;Join operation is essential for data manipulation and filtering in both RDBMS and distributed systems.
There are different types of joins, such as inner, left outer, right outer, semi, etc.
While inner join of data was relatively easy in earlier versions of spark, all of the other types required to specify join expression.
There are even more difficulties if join uses two or more columns.&lt;/p&gt;

&lt;p&gt;Join expressions are not that easy because they require additional DataFrame manipulations, such as column rename and further drop.
If the column has the same name in both data frames, it would not be dropped automatically and cause problems with future select.&lt;/p&gt;

&lt;p&gt;Suppose we have another DataFrame&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val df2 = sc.parallelize(Array(
    (&amp;quot;one&amp;quot;, &amp;quot;A&amp;quot;, 5), (&amp;quot;two&amp;quot;, &amp;quot;A&amp;quot;, 6)
)).toDF(&amp;quot;key1&amp;quot;, &amp;quot;key2&amp;quot;, &amp;quot;value2&amp;quot;)
df2.show()

+----+----+------+
|key1|key2|value2|
+----+----+------+
| one|   A|     5|
| two|   A|     6|
+----+----+------+
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Outer join prior to 1.6 could only be done using join expression:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;val joined = df.join(df2, df(&amp;quot;key1&amp;quot;) === df2(&amp;quot;key1&amp;quot;) &amp;amp;&amp;amp; df(&amp;quot;key2&amp;quot;) === df2(&amp;quot;key2&amp;quot;), &amp;quot;left_outer&amp;quot;)
joined.show()

+----+----+-----+----+----+------+
|key1|key2|value|key1|key2|value2|
+----+----+-----+----+----+------+
| two|   A|    3| two|   A|     6|
| two|   B|    4|null|null|  null|
| one|   A|    1| one|   A|     5|
| one|   B|    2|null|null|  null|
+----+----+-----+----+----+------+
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Result data frame has duplicated column names, any operations with them would throw an error&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;joined.select(&amp;quot;key2&amp;quot;)

org.apache.spark.sql.AnalysisException: Reference &#39;key2&#39; is ambiguous, could be: key2#28, key2#34.;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To avoid duplication, one possible to rename columns before and drop them after the join.
The code in this case becomes messy and requires explanation.
Spark 1.6 simplifies &lt;a href=&#34;https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.DataFrame&#34;&gt;join&lt;/a&gt; and allows to write&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-scala&#34;&gt;df.join(df2, Seq(&amp;quot;key1&amp;quot;, &amp;quot;key2&amp;quot;), &amp;quot;left_outer&amp;quot;).show()

+----+----+-----+------+
|key1|key2|value|value2|
+----+----+-----+------+
| two|   A|    3|     6|
| two|   B|    4|  null|
| one|   A|    1|     5|
| one|   B|    2|  null|
+----+----+-----+------+
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This syntax is much easier to read.&lt;/p&gt;

&lt;h3 id=&#34;5-quantilediscretizer-feature-transformer:8ab4cd76c2e48d03608ec5aca1374ea6&#34;&gt;5. QuantileDiscretizer feature transformer&lt;/h3&gt;

&lt;p&gt;Feature engineering is a big part of data mining.
Usually, data scientists try a lot of different approaches and at the end run some black box algorithm, such as random forest or xgboost.
The more features generated in the beginning, the better.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.ml.feature.QuantileDiscretizer&#34;&gt;QuantileDiscretizer&lt;/a&gt; is still experimental, but already available.
It allows splitting feature into buckets, based on value&amp;rsquo;s quantiles.&lt;/p&gt;

&lt;h3 id=&#34;conclusion:8ab4cd76c2e48d03608ec5aca1374ea6&#34;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;Apache Spark is a dynamic project, every version brings a lot of new features.
Despite it offers excellent data manipulation tools, it is still quite weak in terms of data mining.
Spark niche is a Big Data, where familiar techniques might simply not work.&lt;/p&gt;

&lt;p&gt;It is worthwhile to follow Spark updates.
Based on several previous versions, every one of them brought significant functionality to the tool.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Go versions, how to make updates easier</title>
      <link>http://kirillpavlov.com/blog/2016/02/20/go-versions-how-to-make-updates-easier/</link>
      <pubDate>Sat, 20 Feb 2016 23:06:18 +0800</pubDate>
      
      <guid>http://kirillpavlov.com/blog/2016/02/20/go-versions-how-to-make-updates-easier/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://golang.org/&#34;&gt;Go&lt;/a&gt; is an open source programming language that makes it easy to build simple, reliable, and efficient software.&lt;/p&gt;

&lt;p&gt;Because of its rapid development, there is an issue with version updates.
It requires not only download and compile new version, but also update &lt;code&gt;$GOROOT&lt;/code&gt; and &lt;code&gt;$GOPATH&lt;/code&gt; environment variables.&lt;/p&gt;

&lt;p&gt;One way to simplify this process is to use version manager, such as &lt;a href=&#34;https://github.com/moovweb/gvm&#34;&gt;gvm&lt;/a&gt;.
Installations process is super easy:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;bash &amp;lt; &amp;lt;(curl -s -S -L https://raw.githubusercontent.com/moovweb/gvm/master/binscripts/gvm-installer)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To install proper version of Go use:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;gvm install go1.6
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As simple as that.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Get random lines from file with bash</title>
      <link>http://kirillpavlov.com/blog/2015/08/27/get-random-lines-from-file-with-bash/</link>
      <pubDate>Thu, 27 Aug 2015 06:18:14 +0000</pubDate>
      
      <guid>http://kirillpavlov.com/blog/2015/08/27/get-random-lines-from-file-with-bash/</guid>
      <description>

&lt;p&gt;Data sampling is one of the duties of data scientists and data engineers.
One may require to split original data into train and test subsets.
How could we do it fast with less amount of code?
This article shows usage of different command line tools for such task.&lt;/p&gt;

&lt;p&gt;There are several ways to get random lines from a file:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Sort lines with random key&lt;/li&gt;
&lt;li&gt;&lt;code&gt;shuf&lt;/code&gt; from GNU core utils&lt;/li&gt;
&lt;li&gt;&lt;code&gt;rl&lt;/code&gt; randomize-lines package&lt;/li&gt;
&lt;li&gt;perl one-liner&lt;/li&gt;
&lt;li&gt;python one-liner&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;All of the approaches would be compared in terms of execution time, tools availability and code complexity. File to be sorted consists of 10M lines:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;FILENAME=&amp;quot;/tmp/random-lines.$$.tmp&amp;quot;
NUMLINES=10000000
seq -f &#39;line %.0f&#39; $NUMLINES &amp;gt; $FILENAME;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;sort:7f16ea4a76eb101e46f16364e2326e6b&#34;&gt;sort&lt;/h2&gt;

&lt;p&gt;Default &lt;code&gt;sort&lt;/code&gt; has option &lt;code&gt;-R&lt;/code&gt;, &lt;code&gt;--random-sort&lt;/code&gt; which sorts lines by random hash. However, if there are two lines with the same content, their hashes would be the same and they would be sorted one after another. To prevent such case, one may possible to make all of the lines unique via adding line number to all of them.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;nl -ba $FILENAME | sort -R | sed &#39;s/.*[0-9]\t//&#39; | head
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Time: 3 min 09.77 sec&lt;/p&gt;

&lt;p&gt;Complexity: medium, need to keep in mind making lines unique&lt;/p&gt;

&lt;p&gt;Availability: good&lt;/p&gt;

&lt;h2 id=&#34;shuf:7f16ea4a76eb101e46f16364e2326e6b&#34;&gt;shuf&lt;/h2&gt;

&lt;p&gt;Another bash tool &lt;code&gt;shuf&lt;/code&gt; on the other hand will sufficiently randomize a list, including not putting duplicate lines next to each other. Another advantage of this tool is it&amp;rsquo;s availability. Being part of GNU core utils it is available on nearly every machine.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;shuf $FILENAME | head
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It has parameter &lt;code&gt;-n&lt;/code&gt; to specify number of lines to output, however based on my tests, it does not speed up the process. Combination with &lt;code&gt;head&lt;/code&gt; works better.&lt;/p&gt;

&lt;p&gt;Time: 0.14 sec&lt;/p&gt;

&lt;p&gt;Complexity: easy&lt;/p&gt;

&lt;p&gt;Availability: good&lt;/p&gt;

&lt;h2 id=&#34;randomized-lines:7f16ea4a76eb101e46f16364e2326e6b&#34;&gt;randomized-lines&lt;/h2&gt;

&lt;p&gt;Tool &lt;code&gt;rl&lt;/code&gt; from &lt;a href=&#34;http://manpages.ubuntu.com/manpages/wily/en/man1/rl.1.html&#34;&gt;randomize-lines&lt;/a&gt; package makes random sampling easy, however, not every machine has it. As mentioned in it&amp;rsquo;s description: &amp;ldquo;It does this with only a single pass over the input while trying to use as little memory as possible&amp;rdquo;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;rl $FILENAME | head
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Time: 0.68 sec&lt;/p&gt;

&lt;p&gt;Complexity: easy&lt;/p&gt;

&lt;p&gt;Availability: bad, need to install from external repository&lt;/p&gt;

&lt;h2 id=&#34;perl:7f16ea4a76eb101e46f16364e2326e6b&#34;&gt;perl&lt;/h2&gt;

&lt;p&gt;Perl is a good language for text processing. For those developers, who are less familiar with bash, it might be native to try it first.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cat $FILENAME | perl -MList::Util=shuffle -e &#39;print shuffle(&amp;lt;STDIN&amp;gt;);&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Time: 2.11 sec&lt;/p&gt;

&lt;p&gt;Availability: medium, some of the machines might not have it&lt;/p&gt;

&lt;p&gt;Complexity: medium, need to remember how to call perl from bash and include libraries&lt;/p&gt;

&lt;h2 id=&#34;python:7f16ea4a76eb101e46f16364e2326e6b&#34;&gt;python&lt;/h2&gt;

&lt;p&gt;Python is among most popular programming languages. Nowadays it exists on nearly every machine and a lot of developers worked with it at least once. It has library to work with random numbers and shuffles. As well as perl, it could be invoked from bash.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;python -c &amp;quot;import random, sys; lines = open(sys.argv[1]).readlines(); random.shuffle(lines); print &#39;&#39;.join(lines),&amp;quot; $FILENAME
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Script execution is inefficient, it requires to store data in memory.&lt;/p&gt;

&lt;p&gt;Time: 6.92 sec&lt;/p&gt;

&lt;p&gt;Availability: medium, some of the machines might not have it&lt;/p&gt;

&lt;p&gt;Complexity: medium, need to remember how to call perl from bash and include libraries&lt;/p&gt;

&lt;h2 id=&#34;conclusion:7f16ea4a76eb101e46f16364e2326e6b&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;To sample random lines from command line, default &lt;code&gt;shuf&lt;/code&gt; from core utils is probably the best choice. It is very easy to use and outperforms others in term of execution time.
However, everything depends on a task. For machine learning problems sampling is not a bottleneck and might not require fastest execution.&lt;/p&gt;

&lt;h2 id=&#34;appendix:7f16ea4a76eb101e46f16364e2326e6b&#34;&gt;Appendix&lt;/h2&gt;

&lt;p&gt;Gist with benchmark file:
&lt;script src=&#34;//gist.github.com/34836af4fa1d6c2a0dfa.js&#34;&gt;&lt;/script&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Static site generator for personal blog</title>
      <link>http://kirillpavlov.com/blog/2015/08/22/static-site-generator-for-personal-blog/</link>
      <pubDate>Sat, 22 Aug 2015 23:31:19 +0800</pubDate>
      
      <guid>http://kirillpavlov.com/blog/2015/08/22/static-site-generator-for-personal-blog/</guid>
      <description>&lt;p&gt;Many of us would like to have personal identity in the Internet, write blog, share pictures, code and discuss interesting topics.
For tech related articles social networks would not be enought and we should look for personal blog or website solution.
Here I would like to explain some ideas behing my choice &amp;ndash; &lt;a href=&#34;https://gohugo.io&#34;&gt;hugo&lt;/a&gt;, static site generator written in &lt;a href=&#34;https://golang.org/&#34;&gt;Go&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;First of all, let us write down requirements for personal page:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Web site should work even if we dont have time to support it&lt;/li&gt;
&lt;li&gt;It should support custom domains&lt;/li&gt;
&lt;li&gt;In case of blog, we should be able to add articles easily and deployment should not be problem&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A while ago I had personal page, stored on virtual machine in some cloud service.
This requires me to pay for VM and causes deployment difficulties.
I realized, that solution should be different.&lt;/p&gt;

&lt;p&gt;WordPress offers good service, but price of custom domain makes use of it questionable.
My decision was to use static site generator and deploy it to GitHub, because it is free.
I did not want to customise site a lot from the beginning, content is more important at that period.
Moreover, additional tools, such as Google Analytics and Discus comes with framework.&lt;/p&gt;

&lt;p&gt;There are &lt;a href=&#34;https://www.staticgen.com/&#34;&gt;a lot of static site generators&lt;/a&gt; on the market.
How to choose right one?
My goal was to choose something simple, yet flexible to be able to use it in other projects as well.&lt;/p&gt;

&lt;p&gt;First of all I checked python Pelican, because of my language knowledge.
It looks very similar to Django.
I did not really find it interesting and it&amp;rsquo;s own website was a bit ugly.&lt;/p&gt;

&lt;p&gt;Next, I try JavaScript based generators.
From my point of view, technology itself should be as close to frontend development as possible.
For example, I would rather go for JavaScript instead of Ruby.
I was not able to setup Assemble in 20-30 minutes and found it not easy to work with.
Another JavaScript tools I try were Metalsmith and Hexo.
They require their custom plugins for everything and I don&amp;rsquo;t understand, why it is better than more generic plugins of Grunt or Gulp.&lt;/p&gt;

&lt;p&gt;Next candidate was Jekyll.
It has at least twice as more GitHub stars, than second popular solution.
It is also default GitHub pages solution.
Frankly speaking, Jekyll looks good, but a bit big, so it might be difficult to write own plugins.
At that point of time, I wanted to avoid Ruby and try something else.&lt;/p&gt;

&lt;p&gt;My final choice was Hugo.
It is program, written in Golang, which provides functionality to create, develop and build static website.
As advantages I would like to mention:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Blazing fast build time (under 0.1 sec)&lt;/li&gt;
&lt;li&gt;Tag support: it generates search result pages for every tag used&lt;/li&gt;
&lt;li&gt;It has not only blog support, user could create any page with any url&lt;/li&gt;
&lt;li&gt;Google Analytics, Discuss, Gravatar, Social integration come out of the box&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;During development I use &lt;em&gt;develop&lt;/em&gt; branch for source code.
Hugo builds statis pages in &lt;em&gt;public&lt;/em&gt; folder, which is pushed to master branch using git-subtree.
You could read about this technique &lt;a href=&#34;http://gohugo.io/tutorials/github-pages-blog/#configure-git-workflow&#34;&gt;here&lt;/a&gt;.
To simplify deployment, there is Makefile command with following code:&lt;/p&gt;

&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;hugo
git add -A
git commit -m &lt;span style=&#34;color: #e6db74&#34;&gt;&amp;quot;rebuilding site &amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;$(&lt;/span&gt;shell date&lt;span style=&#34;color: #66d9ef&#34;&gt;)&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;&amp;quot;&lt;/span&gt;
git push origin develop
git subtree push --prefix&lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt;public git@github.com:pavlov99/pavlov99.github.com.git master
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I would like to recommend Hugo for anybody, who wants to build static pages.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>About Me</title>
      <link>http://kirillpavlov.com/about/</link>
      <pubDate>Sun, 09 Aug 2015 16:20:37 +0800</pubDate>
      
      <guid>http://kirillpavlov.com/about/</guid>
      <description>

&lt;p&gt;Hi! My name is Kirill Pavlov, I&amp;rsquo;m a data scientist and software engeneer.
While I&amp;rsquo;m working on content update, check out my &lt;a href=&#34;http://kirillpavlov.com/cv/cv-kirill-pavlov.pdf&#34;&gt;CV&lt;/a&gt;,
&lt;a href=&#34;http://resume.github.io/?pavlov99&#34;&gt;github resume&lt;/a&gt; and &lt;a href=&#34;http://osrc.dfm.io/pavlov99&#34;&gt;github report card&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I am also doing project Euler tasks, you could track my progress here:
&lt;img src=&#34;https://projecteuler.net/profile/pavlov99.png&#34; alt=&#34;Project Euler badge&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;my-name:6083a88ee3411b0d17ce02d738f69d47&#34;&gt;My name&lt;/h2&gt;

&lt;p&gt;My first name is &amp;ldquo;Kirill&amp;rdquo; and my last name is &amp;ldquo;Pavlov&amp;rdquo;.
This name &lt;a href=&#34;https://en.wikipedia.org/wiki/Kirill&#34;&gt;came from Greek&lt;/a&gt;.
One of the inventors of &lt;a href=&#34;https://en.wikipedia.org/wiki/Cyrillic_alphabets&#34;&gt;Cyrillic Alpabet&lt;/a&gt; is Saint Cyrill, our names are considered the same .&lt;/p&gt;

&lt;p&gt;In English my name is pronounced as [k&amp;rsquo;iriɛl p&amp;rsquo;avlov].
My Chinese name is 巴吉霖 (bā jí lín).&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>